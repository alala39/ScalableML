{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sonnet MNIST Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dm-sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sonnet is an object-oriented library written in Python. It was released by DeepMind in 2017. \n",
    "\n",
    "Sonnet intends to cleanly separate the following two aspects of building computation graphs from objects: \n",
    "\n",
    "The configuration of objects called modules \n",
    "The connection of objects to computation graphs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modules are defined as sub-classes of the abstract class sonnet.AbstractModule. \n",
    "\n",
    "The following modules are available in Sonnet: \n",
    "\n",
    "Basic modules: AddBias, BatchApply, BatchFlatten, BatchReshape, FlattenTrailingDimensions, Linear, MergeDims, SelectInput, SliceByDim, TileByDim, and TrainableVariable \n",
    "\n",
    "Recurrent modules: DeepRNN, ModelRNN, VanillaRNN, BatchNormLSTM, GRU, and LSTM \n",
    "\n",
    "Recurrent + ConvNet modules: Conv1DLSTM and Conv2DLSTM ConvNet modules Conv1D, Conv2D, Conv3D, Conv1DTranspose, Conv2DTranspose, Conv3DTranspose, DepthWiseConv2D, InPlaneConv2D, and SeparableConv2D \n",
    "\n",
    "ResidualNets: Residual, ResidualCore, and SkipConnectionCore \n",
    "\n",
    "Others: BatchNorm, LayerNorm, clip_gradient, and scale_gradient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "import os\n",
    "import sonnet as snt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(snt.AbstractModule):\n",
    "\n",
    "    def __init__(self, mnist_part, batch_size, name='MNIST'):\n",
    "\n",
    "        super(MNIST, self).__init__(name=name)\n",
    "\n",
    "        self._X = tf.constant(mnist_part.images, dtype=tf.float32)\n",
    "        self._Y = tf.constant(mnist_part.labels, dtype=tf.float32)\n",
    "        self._batch_size = batch_size\n",
    "        self._M = mnist_part.num_examples\n",
    "\n",
    "    def _build(self):\n",
    "        idx = tf.random_uniform([self._batch_size], 0, self._M, tf.int64)\n",
    "        X = tf.gather(self._X, idx)\n",
    "        Y = tf.gather(self._Y, idx)\n",
    "        return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(snt.AbstractModule):\n",
    "    def __init__(self, output_sizes, name='mlp'):\n",
    "        super(MLP, self).__init__(name=name)\n",
    "\n",
    "        self._layers = []\n",
    "\n",
    "        for output_size in output_sizes:\n",
    "            self._layers.append(snt.Linear(output_size=output_size))\n",
    "\n",
    "    def _build(self, X):\n",
    "\n",
    "        # add the input layer\n",
    "        model = tf.sigmoid(self._layers[0](X))\n",
    "\n",
    "        # add hidden layers\n",
    "        for i in range(1, len(self._layers) - 1):\n",
    "            model = tf.sigmoid(self._layers[i](model))\n",
    "\n",
    "        # add output layer\n",
    "        model = tf.nn.softmax(self._layers[len(self._layers) - 1](model))\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_classes = 10\n",
    "n_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-b3107af94e9c>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(os.path.join('.', 'mnist'),\n",
    "                                  one_hot=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MNIST(mnist.train, batch_size=batch_size)\n",
    "test = MNIST(mnist.test, batch_size=batch_size)\n",
    "\n",
    "X_train, Y_train = train()\n",
    "X_test, Y_test = test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP([20, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_hat = model(X_train)\n",
    "Y_test_hat = model(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(Y_hat, Y):\n",
    "    return -tf.reduce_sum(Y * tf.log(Y_hat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train = loss(Y_train_hat, Y_train)\n",
    "L_test = loss(Y_test_hat, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(\n",
    "    learning_rate=0.01).minimize(L_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Training Loss : 240.02566528320312\n",
      "Epoch : 1 Training Loss : 224.71572875976562\n",
      "Epoch : 2 Training Loss : 224.919189453125\n",
      "Epoch : 3 Training Loss : 213.5795440673828\n",
      "Epoch : 4 Training Loss : 214.39303588867188\n",
      "Epoch : 5 Training Loss : 212.46658325195312\n",
      "Epoch : 6 Training Loss : 201.7828826904297\n",
      "Epoch : 7 Training Loss : 202.36135864257812\n",
      "Epoch : 8 Training Loss : 197.58628845214844\n",
      "Epoch : 9 Training Loss : 191.34939575195312\n",
      "Test loss : 180.21218872070312\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as tfs:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        loss_val, _ = tfs.run((L_train, optimizer))\n",
    "        print('Epoch : {} Training Loss : {}'.format(epoch, loss_val))\n",
    "\n",
    "    loss_val = tfs.run(L_test)\n",
    "    print('Test loss : {}'.format(loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
